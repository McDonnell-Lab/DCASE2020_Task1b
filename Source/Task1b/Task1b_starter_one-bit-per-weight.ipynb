{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n this v2, don't quadruple the final layer\n",
    "#in this v3, lower the weight decay\n",
    "#in this v5, attempt class balance\n",
    "#v5 worked! In this v7, try increasing the batch size\n",
    "#v8: batch size increase may have been slightly detrimental.\n",
    "    #- go back to batch size 33\n",
    "    #- here experiment with no deltas\n",
    "#v9 - deltas add no value to performance. Here try a substantially smaller model\n",
    "    #-result: hardly lost an accuracy!\n",
    "#v10 put batch size back done and wd back up\n",
    "\n",
    "#this v2 - four time larger model\n",
    "\n",
    "#v3: change kernel for penultimate layer to 3x3 not 1x1\n",
    "\n",
    "#v4: v3 seemed to help slightly\n",
    "# - try lwer weight decay, and load spectrograms from disk\n",
    "\n",
    "#v5: use larger spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a GPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdmcdonn/anaconda3/envs/April2019/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mdmcdonn/anaconda3/envs/April2019/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mdmcdonn/anaconda3/envs/April2019/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mdmcdonn/anaconda3/envs/April2019/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mdmcdonn/anaconda3/envs/April2019/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mdmcdonn/anaconda3/envs/April2019/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librosa version =  0.6.3\n",
      "Pysoundfile version =  0.10.2\n",
      "keras version =  2.2.4-tf\n",
      "tensorflow version =  1.13.1\n"
     ]
    }
   ],
   "source": [
    "#imports \n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sound\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "print(\"Librosa version = \",librosa.__version__)\n",
    "print(\"Pysoundfile version = \",sound.__version__)\n",
    "print(\"keras version = \",tensorflow.keras.__version__)\n",
    "print(\"tensorflow version = \",tensorflow.__version__)\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "from NNets import model_resnet_updated\n",
    "\n",
    "from DCASE_training_functions import LR_WarmRestart, MixupGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BasePath = '../../Data/TAU-urban-acoustic-scenes-2020-3class-development/'\n",
    "TrainFile = BasePath + 'evaluation_setup/fold1_train.csv'\n",
    "ValFile = BasePath + 'evaluation_setup/fold1_evaluate.csv'\n",
    "sr = 48000\n",
    "num_audio_channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "SampleDuration = 10\n",
    "\n",
    "#log-mel spectrogram parameters\n",
    "NumFreqBins = 256\n",
    "NumFFTPoints = 4996\n",
    "HopLength = int(NumFFTPoints/4)\n",
    "NumTimeBins = int(np.ceil(SampleDuration*sr/HopLength))\n",
    "\n",
    "#training parameters\n",
    "init_lr = 0.1\n",
    "batch_size = 30 #divisible by 3, due to class balance strategy\n",
    "num_epochs = 126\n",
    "mixup_alpha = 0.4\n",
    "crop_length = 400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#load filenames and labels\n",
    "dev_train_df = pd.read_csv(TrainFile,sep='\\t', encoding='ASCII')\n",
    "dev_val_df = pd.read_csv(ValFile,sep='\\t', encoding='ASCII')\n",
    "wavpaths_train = dev_train_df['filename'].tolist()\n",
    "wavpaths_val = dev_val_df['filename'].tolist()\n",
    "y_train_labels =  dev_train_df['scene_label'].astype('category').cat.codes.values\n",
    "y_val_labels =  dev_val_df['scene_label'].astype('category').cat.codes.values\n",
    "\n",
    "ClassNames = np.unique(dev_train_df['scene_label'])\n",
    "NumClasses = len(ClassNames)\n",
    "\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train_labels, NumClasses)\n",
    "y_val = tensorflow.keras.utils.to_categorical(y_val_labels, NumClasses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['indoor', 'outdoor', 'transportation'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClassNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_train=np.load('Task1b_LM_train_256_4096.npy')\n",
    "LM_val=np.load('Task1b_LM_val_256_4096.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_train = np.log(LM_train+1e-8)\n",
    "LM_val = np.log(LM_val+1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9185, 256, 469, 2), (4185, 256, 469, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM_train.shape,LM_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mdmcdonn/anaconda3/envs/April2019/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, None, 2) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 128, None, 2) 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128, None, 2) 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1 (BatchNo (None, 128, None, 2) 8           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_1 (Batch (None, 128, None, 2) 8           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d (BinaryConv2D)    (None, 128, None, 25 450         batch_normalization_v1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_1 (BinaryConv2D)  (None, 128, None, 25 450         batch_normalization_v1_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_2 (Batch (None, 128, None, 25 50          binary_conv2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_3 (Batch (None, 128, None, 25 50          binary_conv2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128, None, 25 0           batch_normalization_v1_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, None, 25 0           batch_normalization_v1_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_2 (BinaryConv2D)  (None, 128, None, 25 5625        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_3 (BinaryConv2D)  (None, 128, None, 25 5625        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_4 (Batch (None, 128, None, 25 50          binary_conv2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_5 (Batch (None, 128, None, 25 50          binary_conv2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, None, 25 0           batch_normalization_v1_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, None, 25 0           batch_normalization_v1_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_4 (BinaryConv2D)  (None, 128, None, 25 5625        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_5 (BinaryConv2D)  (None, 128, None, 25 5625        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 128, None, 25 0           binary_conv2d_4[0][0]            \n",
      "                                                                 binary_conv2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, None, 25 0           binary_conv2d_5[0][0]            \n",
      "                                                                 binary_conv2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_6 (Batch (None, 128, None, 25 50          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_7 (Batch (None, 128, None, 25 50          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, None, 25 0           batch_normalization_v1_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, None, 25 0           batch_normalization_v1_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_6 (BinaryConv2D)  (None, 128, None, 25 5625        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_7 (BinaryConv2D)  (None, 128, None, 25 5625        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_8 (Batch (None, 128, None, 25 50          binary_conv2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_9 (Batch (None, 128, None, 25 50          binary_conv2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128, None, 25 0           batch_normalization_v1_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 128, None, 25 0           batch_normalization_v1_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_8 (BinaryConv2D)  (None, 128, None, 25 5625        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_9 (BinaryConv2D)  (None, 128, None, 25 5625        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128, None, 25 0           binary_conv2d_8[0][0]            \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, None, 25 0           binary_conv2d_9[0][0]            \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_10 (Batc (None, 128, None, 25 50          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_11 (Batc (None, 128, None, 25 50          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 128, None, 25 0           batch_normalization_v1_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 128, None, 25 0           batch_normalization_v1_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_10 (BinaryConv2D) (None, 128, None, 50 11250       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_11 (BinaryConv2D) (None, 128, None, 50 11250       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_12 (Batc (None, 128, None, 50 100         binary_conv2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 128, None, 25 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_13 (Batc (None, 128, None, 50 100         binary_conv2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 128, None, 25 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 128, None, 50 0           batch_normalization_v1_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 128, None, 25 0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 128, None, 50 0           batch_normalization_v1_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 128, None, 25 0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_12 (BinaryConv2D) (None, 128, None, 50 22500       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128, None, 50 0           average_pooling2d[0][0]          \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_13 (BinaryConv2D) (None, 128, None, 50 22500       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, None, 50 0           average_pooling2d_1[0][0]        \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, None, 50 0           binary_conv2d_12[0][0]           \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 128, None, 50 0           binary_conv2d_13[0][0]           \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_14 (Batc (None, 128, None, 50 100         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_15 (Batc (None, 128, None, 50 100         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128, None, 50 0           batch_normalization_v1_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 128, None, 50 0           batch_normalization_v1_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_14 (BinaryConv2D) (None, 128, None, 50 22500       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_15 (BinaryConv2D) (None, 128, None, 50 22500       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_16 (Batc (None, 128, None, 50 100         binary_conv2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_17 (Batc (None, 128, None, 50 100         binary_conv2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, None, 50 0           batch_normalization_v1_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, None, 50 0           batch_normalization_v1_17[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_16 (BinaryConv2D) (None, 128, None, 50 22500       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_17 (BinaryConv2D) (None, 128, None, 50 22500       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 128, None, 50 0           binary_conv2d_16[0][0]           \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 128, None, 50 0           binary_conv2d_17[0][0]           \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_18 (Batc (None, 128, None, 50 100         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_19 (Batc (None, 128, None, 50 100         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 128, None, 50 0           batch_normalization_v1_18[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 128, None, 50 0           batch_normalization_v1_19[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_18 (BinaryConv2D) (None, 128, None, 10 45000       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_19 (BinaryConv2D) (None, 128, None, 10 45000       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_20 (Batc (None, 128, None, 10 200         binary_conv2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 128, None, 50 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_21 (Batc (None, 128, None, 10 200         binary_conv2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 128, None, 50 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 128, None, 10 0           batch_normalization_v1_20[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 128, None, 50 0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 128, None, 10 0           batch_normalization_v1_21[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 128, None, 50 0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_20 (BinaryConv2D) (None, 128, None, 10 90000       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, None, 10 0           average_pooling2d_2[0][0]        \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_21 (BinaryConv2D) (None, 128, None, 10 90000       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, None, 10 0           average_pooling2d_3[0][0]        \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 128, None, 10 0           binary_conv2d_20[0][0]           \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 128, None, 10 0           binary_conv2d_21[0][0]           \n",
      "                                                                 concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_22 (Batc (None, 128, None, 10 200         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_23 (Batc (None, 128, None, 10 200         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 128, None, 10 0           batch_normalization_v1_22[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 128, None, 10 0           batch_normalization_v1_23[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_22 (BinaryConv2D) (None, 128, None, 10 90000       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_23 (BinaryConv2D) (None, 128, None, 10 90000       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_24 (Batc (None, 128, None, 10 200         binary_conv2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_25 (Batc (None, 128, None, 10 200         binary_conv2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 128, None, 10 0           batch_normalization_v1_24[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 128, None, 10 0           batch_normalization_v1_25[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_24 (BinaryConv2D) (None, 128, None, 10 90000       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_25 (BinaryConv2D) (None, 128, None, 10 90000       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 128, None, 10 0           binary_conv2d_24[0][0]           \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 128, None, 10 0           binary_conv2d_25[0][0]           \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_26 (Batc (None, 128, None, 10 200         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_27 (Batc (None, 128, None, 10 200         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 128, None, 10 0           batch_normalization_v1_26[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 128, None, 10 0           batch_normalization_v1_27[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_26 (BinaryConv2D) (None, 128, None, 20 180000      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_27 (BinaryConv2D) (None, 128, None, 20 180000      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_28 (Batc (None, 128, None, 20 400         binary_conv2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 128, None, 10 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_29 (Batc (None, 128, None, 20 400         binary_conv2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 128, None, 10 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 128, None, 20 0           batch_normalization_v1_28[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 128, None, 10 0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 128, None, 20 0           batch_normalization_v1_29[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 128, None, 10 0           average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_28 (BinaryConv2D) (None, 128, None, 20 360000      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, None, 20 0           average_pooling2d_4[0][0]        \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_29 (BinaryConv2D) (None, 128, None, 20 360000      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 128, None, 20 0           average_pooling2d_5[0][0]        \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 128, None, 20 0           binary_conv2d_28[0][0]           \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 128, None, 20 0           binary_conv2d_29[0][0]           \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_30 (Batc (None, 128, None, 20 400         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_31 (Batc (None, 128, None, 20 400         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 128, None, 20 0           batch_normalization_v1_30[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 128, None, 20 0           batch_normalization_v1_31[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_30 (BinaryConv2D) (None, 128, None, 20 360000      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_31 (BinaryConv2D) (None, 128, None, 20 360000      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_32 (Batc (None, 128, None, 20 400         binary_conv2d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_33 (Batc (None, 128, None, 20 400         binary_conv2d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 128, None, 20 0           batch_normalization_v1_32[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 128, None, 20 0           batch_normalization_v1_33[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_32 (BinaryConv2D) (None, 128, None, 20 360000      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_33 (BinaryConv2D) (None, 128, None, 20 360000      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 128, None, 20 0           binary_conv2d_32[0][0]           \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 128, None, 20 0           binary_conv2d_33[0][0]           \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 256, None, 20 0           add_14[0][0]                     \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_34 (Batc (None, 256, None, 20 400         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 256, None, 20 0           batch_normalization_v1_34[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_34 (BinaryConv2D) (None, 256, None, 40 720000      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_35 (Batc (None, 256, None, 40 800         binary_conv2d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "binary_conv2d_35 (BinaryConv2D) (None, 256, None, 3) 1200        batch_normalization_v1_35[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_36 (Batc (None, 256, None, 3) 12          binary_conv2d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 3)            0           batch_normalization_v1_36[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 3)            0           global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 4,081,128\n",
      "Trainable params: 4,074,614\n",
      "Non-trainable params: 6,514\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#create and compile the model\n",
    "wd = 5e-4\n",
    "num_filters=25\n",
    "\n",
    "model = model_resnet_updated(NumClasses,\n",
    "                     input_shape =[NumFreqBins,None,num_audio_channels], \n",
    "                     num_filters =num_filters,\n",
    "                     wd=wd,binarise_weights=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer =SGD(lr=init_lr,decay=0, momentum=0.9, nesterov=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create data generator\n",
    "TrainDataGen = MixupGenerator(LM_train, \n",
    "                              y_train, \n",
    "                              batch_size=batch_size,\n",
    "                              alpha=mixup_alpha,\n",
    "                              crop_length=crop_length,\n",
    "                              UseBalance=False)\n",
    "\n",
    "steps_per_epoch =TrainDataGen.__len__()\n",
    "lr_scheduler = LR_WarmRestart(nbatch=steps_per_epoch,\n",
    "                              initial_lr=init_lr, min_lr=init_lr*1e-4,\n",
    "                              epochs_restart = [1.0,3.0, 7.0, 15.0, 31.0, 63.0,127.0,255.0]) \n",
    "callbacks = [lr_scheduler]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mdmcdonn/anaconda3/envs/April2019/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      " Start of Epoch Learning Rate = 0.100000\n",
      "Epoch 1/126\n",
      "4185/4185 [==============================] - 29s 7ms/sample - loss: 2.7189 - acc: 0.7811\n",
      "\n",
      " End of Epoch Learning Rate = 0.050005\n",
      "306/306 [==============================] - 220s 719ms/step - loss: 3.4817 - acc: 0.6853 - val_loss: 2.7172 - val_acc: 0.7811\n",
      "\n",
      " Start of Epoch Learning Rate = 0.050005\n",
      "Epoch 2/126\n",
      "4185/4185 [==============================] - 28s 7ms/sample - loss: 2.3387 - acc: 0.8397\n",
      "\n",
      " End of Epoch Learning Rate = 0.000010\n",
      "306/306 [==============================] - 216s 704ms/step - loss: 2.5603 - acc: 0.8065 - val_loss: 2.3391 - val_acc: 0.8397\n",
      "\n",
      " Start of Epoch Learning Rate = 0.100000\n",
      "Epoch 3/126\n",
      "4185/4185 [==============================] - 27s 7ms/sample - loss: 1.6456 - acc: 0.8010\n",
      "\n",
      " End of Epoch Learning Rate = 0.085357\n",
      "306/306 [==============================] - 215s 704ms/step - loss: 2.1222 - acc: 0.7847 - val_loss: 1.6439 - val_acc: 0.8010\n",
      "\n",
      " Start of Epoch Learning Rate = 0.085357\n",
      "Epoch 4/126\n",
      "4185/4185 [==============================] - 28s 7ms/sample - loss: 1.2654 - acc: 0.7620\n",
      "\n",
      " End of Epoch Learning Rate = 0.050005\n",
      "306/306 [==============================] - 215s 704ms/step - loss: 1.4798 - acc: 0.8234 - val_loss: 1.2649 - val_acc: 0.7620\n",
      "\n",
      " Start of Epoch Learning Rate = 0.050005\n",
      "Epoch 5/126\n",
      "4185/4185 [==============================] - 28s 7ms/sample - loss: 1.2083 - acc: 0.7295\n",
      "\n",
      " End of Epoch Learning Rate = 0.014653\n",
      "306/306 [==============================] - 216s 705ms/step - loss: 1.1973 - acc: 0.8495 - val_loss: 1.2095 - val_acc: 0.7295\n",
      "\n",
      " Start of Epoch Learning Rate = 0.014653\n",
      "Epoch 6/126\n",
      "4185/4185 [==============================] - 27s 7ms/sample - loss: 0.9497 - acc: 0.8667\n",
      "\n",
      " End of Epoch Learning Rate = 0.000010\n",
      "306/306 [==============================] - 215s 704ms/step - loss: 1.0919 - acc: 0.8744 - val_loss: 0.9497 - val_acc: 0.8667\n",
      "\n",
      " Start of Epoch Learning Rate = 0.100000\n",
      "Epoch 7/126\n",
      "4185/4185 [==============================] - 27s 6ms/sample - loss: 0.7637 - acc: 0.8208\n",
      "\n",
      " End of Epoch Learning Rate = 0.096194\n",
      "306/306 [==============================] - 215s 702ms/step - loss: 1.0604 - acc: 0.8186 - val_loss: 0.7633 - val_acc: 0.8208\n",
      "\n",
      " Start of Epoch Learning Rate = 0.096194\n",
      "Epoch 8/126\n",
      "4185/4185 [==============================] - 27s 6ms/sample - loss: 0.6608 - acc: 0.8299\n",
      "\n",
      " End of Epoch Learning Rate = 0.085357\n",
      "306/306 [==============================] - 215s 703ms/step - loss: 0.8358 - acc: 0.8389 - val_loss: 0.6593 - val_acc: 0.8299\n",
      "\n",
      " Start of Epoch Learning Rate = 0.085357\n",
      "Epoch 9/126\n",
      "4185/4185 [==============================] - 27s 6ms/sample - loss: 0.8568 - acc: 0.7188\n",
      "\n",
      " End of Epoch Learning Rate = 0.069137\n",
      "306/306 [==============================] - 215s 703ms/step - loss: 0.7239 - acc: 0.8463 - val_loss: 0.8548 - val_acc: 0.7188\n",
      "\n",
      " Start of Epoch Learning Rate = 0.069137\n",
      "Epoch 10/126\n",
      "4185/4185 [==============================] - 27s 6ms/sample - loss: 0.4837 - acc: 0.8650\n",
      "\n",
      " End of Epoch Learning Rate = 0.050005\n",
      "306/306 [==============================] - 215s 703ms/step - loss: 0.6570 - acc: 0.8556 - val_loss: 0.4829 - val_acc: 0.8650\n",
      "\n",
      " Start of Epoch Learning Rate = 0.050005\n",
      "Epoch 11/126\n",
      "4185/4185 [==============================] - 27s 6ms/sample - loss: 0.4515 - acc: 0.8743\n",
      "\n",
      " End of Epoch Learning Rate = 0.030873\n",
      "306/306 [==============================] - 215s 702ms/step - loss: 0.6097 - acc: 0.8617 - val_loss: 0.4503 - val_acc: 0.8743\n",
      "\n",
      " Start of Epoch Learning Rate = 0.030873\n",
      "Epoch 12/126\n",
      "4185/4185 [==============================] - 28s 7ms/sample - loss: 0.7666 - acc: 0.6605\n",
      "\n",
      " End of Epoch Learning Rate = 0.014653\n",
      "306/306 [==============================] - 216s 705ms/step - loss: 0.5681 - acc: 0.8864 - val_loss: 0.7666 - val_acc: 0.6605\n",
      "\n",
      " Start of Epoch Learning Rate = 0.014653\n",
      "Epoch 13/126\n",
      "228/306 [=====================>........] - ETA: 47s - loss: 0.5405 - acc: 0.8889"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "\n",
    "history = model.fit_generator(TrainDataGen,\n",
    "                              validation_data=(LM_val, y_val),\n",
    "                              epochs=num_epochs, \n",
    "                              verbose=1, \n",
    "                              workers=1,\n",
    "                              max_queue_size = 100,\n",
    "                              callbacks=callbacks,\n",
    "                              steps_per_epoch=steps_per_epoch\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('Models/Task1B_Final_weights_v5_noundersampling.h5') #damn - I overwrote these!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.plot(history.history['acc'])\n",
    "plt.ylim([0.8,0.98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(np.arange(0,len(lr_scheduler.lr_used))/np.ceil(LM_train.shape[0]/batch_size),lr_scheduler.lr_used,'-')\n",
    "plt.xlabel('epoch number')\n",
    "plt.ylabel('learning rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['val_acc'][13],history.history['val_acc'][29],history.history['val_acc'][61],history.history['val_acc'][125],history.history['val_acc'][253],history.history['val_acc'][509]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_acc'][450::])\n",
    "plt.plot(history.history['acc'][450::])\n",
    "\n",
    "plt.plot(history.history['val_acc'][0:15])\n",
    "plt.plot(history.history['acc'][0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DCASE_plots\n",
    "#importlib.reload(DCASE_plots)\n",
    "from DCASE_plots import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(LM_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#too many predictions for indoor and outdoor\n",
    "PC_correct =sum( np.argmax(y_val,axis=-1)==np.argmax([1,0.7,0.5]*y_pred,axis=-1))/y_pred.shape[0]\n",
    "PC_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(np.argmax(y_val,axis=-1), np.argmax(y_pred,axis=-1), dev_train_df['scene_label'].unique().tolist(),\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(np.argmax(y_val,axis=-1), np.argmax([1,0.7,0.5]*y_pred,axis=-1), dev_train_df['scene_label'].unique().tolist(),\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "weightings = [1,1,0.5] #justification for transport to bbe higher is each example was used less in training\n",
    "\n",
    "y_pred_val=np.argmax(weightings*y_pred,axis=-1)\n",
    "y_val_labels=np.argmax(y_val,axis=-1)\n",
    "Overall_accuracy = np.sum(y_pred_val==y_val_labels)/LM_val.shape[0]\n",
    "print(\"overall accuracy: \", Overall_accuracy)\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_val_labels,y_pred_val)\n",
    "conf_mat_norm_recall = conf_matrix.astype('float32')/conf_matrix.sum(axis=1)[:,np.newaxis]\n",
    "conf_mat_norm_precision = conf_matrix.astype('float32')/conf_matrix.sum(axis=0)[:,np.newaxis]\n",
    "recall_by_class = np.diagonal(conf_mat_norm_recall)\n",
    "precision_by_class = np.diagonal(conf_mat_norm_precision)\n",
    "mean_recall = np.mean(recall_by_class)\n",
    "mean_precision = np.mean(precision_by_class)\n",
    "\n",
    "print(\"per-class accuracy (recall): \",recall_by_class)\n",
    "print(\"per-class precision: \",precision_by_class)\n",
    "print(\"mean per-class recall: \",mean_recall)\n",
    "print(\"mean per-class precision: \",mean_precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see if batch norm updates well with  this:\n",
    "wd = 5e-4\n",
    "num_filters=25\n",
    "\n",
    "model = model_resnet_updated(NumClasses,\n",
    "                     input_shape =[NumFreqBins,469,num_audio_channels], \n",
    "                     num_filters =num_filters,\n",
    "                     wd=wd,binarise_weights=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer =SGD(lr=1e-3,decay=0, momentum=0.9, nesterov=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.load_weights('Models/Task1B_Final_weights_v5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = model.fit(LM_train, y_train, batch_size=18,\n",
    "#validation_data=(LM_val, y_val),\n",
    "              \n",
    "                              epochs=5, \n",
    "                              verbose=1, \n",
    "                              workers=1,\n",
    "                              max_queue_size = 100,\n",
    "                              \n",
    "                              steps_per_epoch=int(np.ceil(LM_train.shape[0]/batch_size))\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
