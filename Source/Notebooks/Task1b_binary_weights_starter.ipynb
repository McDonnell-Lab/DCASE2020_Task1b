{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a GPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import librosa\n",
    "import soundfile as sound\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "print(\"Librosa version = \",librosa.__version__)\n",
    "print(\"Pysoundfile version = \",sound.__version__)\n",
    "print(\"keras version = \",tensorflow.keras.__version__)\n",
    "print(\"tensorflow version = \",tensorflow.__version__)\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "from NNets import model_resnet_updated\n",
    "from DCASE_training_functions import LR_WarmRestart, MixupGenerator\n",
    "from DCASE_plots import plot_confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BasePath = '../../Data/TAU-urban-acoustic-scenes-2020-3class-development/'\n",
    "TrainFile = BasePath + 'evaluation_setup/fold1_train.csv'\n",
    "ValFile = BasePath + 'evaluation_setup/fold1_evaluate.csv'\n",
    "sr = 48000\n",
    "num_audio_channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleDuration = 10 #seconds\n",
    "\n",
    "#log-mel spectrogram parameters\n",
    "NumFreqBins = 256\n",
    "NumFFTPoints = 4096\n",
    "HopLength = int(NumFFTPoints/4)\n",
    "NumTimeBins = int(np.ceil(SampleDuration*sr/HopLength))\n",
    "\n",
    "#training parameters\n",
    "init_lr = 0.1\n",
    "batch_size = 30 #divisible by 3, due to class balance strategy\n",
    "num_epochs = 126\n",
    "mixup_alpha = 0.4\n",
    "crop_length = 400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load filenames and labels\n",
    "dev_train_df = pd.read_csv(TrainFile,sep='\\t', encoding='ASCII')\n",
    "dev_val_df = pd.read_csv(ValFile,sep='\\t', encoding='ASCII')\n",
    "wavpaths_train = dev_train_df['filename'].tolist()\n",
    "wavpaths_val = dev_val_df['filename'].tolist()\n",
    "y_train_labels =  dev_train_df['scene_label'].astype('category').cat.codes.values\n",
    "y_val_labels =  dev_val_df['scene_label'].astype('category').cat.codes.values\n",
    "\n",
    "ClassNames = np.unique(dev_train_df['scene_label'])\n",
    "NumClasses = len(ClassNames)\n",
    "\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train_labels, NumClasses)\n",
    "y_val = tensorflow.keras.utils.to_categorical(y_val_labels, NumClasses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_train=np.load('Task1b_LM_train_256_4096.npy')\n",
    "LM_val=np.load('Task1b_LM_val_256_4096.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_train = np.log(LM_train+1e-8)\n",
    "LM_val = np.log(LM_val+1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_train.shape,LM_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and compile the model\n",
    "wd = 5e-4\n",
    "num_filters=25\n",
    "\n",
    "model = model_resnet_updated(NumClasses,\n",
    "                     input_shape =[NumFreqBins,None,num_audio_channels], \n",
    "                     num_filters =num_filters,\n",
    "                     wd=wd,binarise_weights=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer =SGD(lr=init_lr,decay=0, momentum=0.9, nesterov=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data generator\n",
    "TrainDataGen = MixupGenerator(LM_train, \n",
    "                              y_train, \n",
    "                              batch_size=batch_size,\n",
    "                              alpha=mixup_alpha,\n",
    "                              crop_length=crop_length,\n",
    "                              UseBalance=False)\n",
    "\n",
    "steps_per_epoch =TrainDataGen.__len__()\n",
    "lr_scheduler = LR_WarmRestart(nbatch=steps_per_epoch,\n",
    "                              initial_lr=init_lr, min_lr=init_lr*1e-4,\n",
    "                              epochs_restart = [1.0,3.0, 7.0, 15.0, 31.0, 63.0,127.0,255.0]) \n",
    "callbacks = [lr_scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train the model\n",
    "history = model.fit_generator(TrainDataGen,\n",
    "                              validation_data=(LM_val, y_val),\n",
    "                              epochs=num_epochs, \n",
    "                              verbose=1, \n",
    "                              workers=1,\n",
    "                              max_queue_size = 100,\n",
    "                              callbacks=callbacks,\n",
    "                              steps_per_epoch=steps_per_epoch\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('Models/Task1B_starter.h5') #damn - I overwrote these!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.plot(history.history['acc'])\n",
    "plt.ylim([0.8,0.98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['val_acc'][13],history.history['val_acc'][29],history.history['val_acc'][61],history.history['val_acc'][125],history.history['val_acc'][253],history.history['val_acc'][509]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(LM_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(np.argmax(y_val,axis=-1), np.argmax(y_pred,axis=-1), dev_train_df['scene_label'].unique().tolist(),\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get metrics\n",
    "\n",
    "weightings = [1,1,1] #justification for transport to bbe higher is each example was used less in training\n",
    "\n",
    "y_pred_val=np.argmax(weightings*y_pred,axis=-1)\n",
    "y_val_labels=np.argmax(y_val,axis=-1)\n",
    "Overall_accuracy = np.sum(y_pred_val==y_val_labels)/LM_val.shape[0]\n",
    "print(\"overall accuracy: \", Overall_accuracy)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_val_labels,y_pred_val)\n",
    "conf_mat_norm_recall = conf_matrix.astype('float32')/conf_matrix.sum(axis=1)[:,np.newaxis]\n",
    "conf_mat_norm_precision = conf_matrix.astype('float32')/conf_matrix.sum(axis=0)[:,np.newaxis]\n",
    "recall_by_class = np.diagonal(conf_mat_norm_recall)\n",
    "precision_by_class = np.diagonal(conf_mat_norm_precision)\n",
    "mean_recall = np.mean(recall_by_class)\n",
    "mean_precision = np.mean(precision_by_class)\n",
    "\n",
    "print(\"per-class accuracy (recall): \",recall_by_class)\n",
    "print(\"per-class precision: \",precision_by_class)\n",
    "print(\"mean per-class recall: \",mean_recall)\n",
    "print(\"mean per-class precision: \",mean_precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
