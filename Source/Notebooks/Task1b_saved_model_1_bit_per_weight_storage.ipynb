{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Mark McDonnell, mark.mcdonnell@unisa.edu.au"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'McDonnell_Task1b_dev_train_val' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdmcdonn/anaconda3/envs/April2019/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mdmcdonn/anaconda3/envs/April2019/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mdmcdonn/anaconda3/envs/April2019/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mdmcdonn/anaconda3/envs/April2019/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mdmcdonn/anaconda3/envs/April2019/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mdmcdonn/anaconda3/envs/April2019/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version =  2.2.4-tf\n",
      "tensorflow version =  1.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdmcdonn/anaconda3/envs/April2019/lib/python3.6/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "#select a GPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "\n",
    "#imports \n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score\n",
    "from scipy.io import savemat,loadmat\n",
    "import soundfile as sound\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "print(\"keras version = \",tensorflow.keras.__version__)\n",
    "print(\"tensorflow version = \",tensorflow.__version__)\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "from NNets import model_resnet_updated_all_binary\n",
    "from DCASE_training_functions_v2 import LR_WarmRestart, MixupGenerator\n",
    "from DCASE_plots import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source data attributes\n",
    "sr = 48000\n",
    "num_audio_channels = 2\n",
    "SampleDuration = 10 #seconds\n",
    "\n",
    "#log-mel spectrogram parameters\n",
    "NumFreqBins = 256\n",
    "NumFFTPoints = 4096\n",
    "HopLength = int(NumFFTPoints/4)\n",
    "NumTimeBins = int(np.ceil(SampleDuration*sr/HopLength))\n",
    "\n",
    "#training parameters\n",
    "init_lr = 0.025\n",
    "batch_size = 32\n",
    "num_epochs = 310\n",
    "mixup_alpha = 0.4\n",
    "crop_length = 400\n",
    "\n",
    "#model parameters\n",
    "wd = 5e-4\n",
    "num_filters=26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes= ['indoor' 'outdoor' 'transportation']\n"
     ]
    }
   ],
   "source": [
    "#class information\n",
    "meta_df = pd.read_csv('../../Data/TAU-urban-acoustic-scenes-2020-3class-development/meta.csv',sep='\\t', encoding='ASCII')\n",
    "ClassNames = np.unique(meta_df['scene_label'])\n",
    "NumClasses = len(ClassNames)\n",
    "print('Classes=',ClassNames)\n",
    "\n",
    "#get  official DCASE 2020 validation dev split:\n",
    "BasePath = '../../Data/TAU-urban-acoustic-scenes-2020-3class-development/'\n",
    "ValFile = BasePath + 'evaluation_setup/fold1_evaluate.csv'\n",
    "dev_val_df = pd.read_csv(ValFile,sep='\\t', encoding='ASCII')\n",
    "wavpaths_val = dev_val_df['filename'].tolist()\n",
    "y_val_labels =  dev_val_df['scene_label'].astype('category').cat.codes.values\n",
    "y_val = tensorflow.keras.utils.to_categorical(y_val_labels, NumClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.load('Task1b_LM_val_256_4096.npy')\n",
    "X_val = np.log(X_val+1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mdmcdonn/anaconda3/envs/April2019/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#define and compile the model\n",
    "inference_model = model_resnet_updated_all_binary(NumClasses,\n",
    "                         input_shape =[NumFreqBins,None,num_audio_channels], \n",
    "                         num_filters =num_filters,\n",
    "                         wd=wd,binarise_weights=True)\n",
    "\n",
    "#load the weights stored in default 32 bit precision, but noting that all conv weights are -1.0 or +1.0\n",
    "inference_model.load_weights('DCASE2020_Task1b_development_example.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_accuracy (%): 96.86977299880526\n"
     ]
    }
   ],
   "source": [
    "#get accuracy for default-saved 32 bit trained weights:\n",
    "y_pred_val = inference_model.predict(X_val)\n",
    "print('Val_accuracy (%):', 100*sum(np.argmax(y_pred_val,-1)==np.argmax(y_val,-1))/y_val.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num binary weights is less than 500kb:  3987000 conv weights = conv weights memory of  486.6943359375   kB\n",
      "Num 32-bit weights (all batch norm parameters) =  6340 ; weights memory =  24.765625   kB\n",
      "Total memory =  511.4599609375   MB\n"
     ]
    }
   ],
   "source": [
    "#Convert model parameters to one bit storage\n",
    "\n",
    "#Note: the constraint in Task 1B is for 500 kB of convolutional or fully connected weights. Batch norm \n",
    "#params explciitly do not count, and can be additional memory.\n",
    "\n",
    "ZeroOneWeightsDict = {}\n",
    "AllParamsDict={}\n",
    "NumBinaryWeights=0.0\n",
    "Num32bitWeights=0.0\n",
    "for layer in inference_model.layers:\n",
    "    #print(layer.name)\n",
    "\n",
    "    if 'conv2d' in layer.name:\n",
    "        ww=layer.get_weights()\n",
    "\n",
    "        #storage using 1 bit booleans\n",
    "        binary_weights = (0.5*(np.sign(ww)+1.0)).astype('bool') #save weights as 0 or 1\n",
    "        ZeroOneWeightsDict[layer.name]=binary_weights\n",
    "        AllParamsDict[layer.name]=binary_weights\n",
    "        NumBinaryWeights+=np.prod(ww[0].shape)\n",
    "    elif 'batch_normalization' in layer.name:\n",
    "        #the saved model also nees floating point batch norm params\n",
    "        ww=layer.get_weights()\n",
    "        AllParamsDict[layer.name]=ww\n",
    "        cc=0\n",
    "        for kk in ww:\n",
    "            #print(cc,layer.name,np.prod(kk.shape))\n",
    "            Num32bitWeights+=np.prod(kk.shape)\n",
    "            cc=cc+1\n",
    "        \n",
    "savemat('FinalModel_01weights.mat',ZeroOneWeightsDict,do_compression=True,long_field_names=True)\n",
    "savemat('FinalModel_allparams.mat',AllParamsDict,do_compression=True,long_field_names=True)\n",
    "\n",
    "WeightsMemory=NumBinaryWeights/8/1024\n",
    "BNMemory=32.0*Num32bitWeights/8/1024\n",
    "print('Num binary weights is less than 500kb: ',int(NumBinaryWeights),'conv weights = conv weights memory of ',WeightsMemory,'  kB')\n",
    "print('Num 32-bit weights (all batch norm parameters) = ',int(Num32bitWeights),'; weights memory = ',BNMemory,'  kB')\n",
    "print('Total memory = ',WeightsMemory+BNMemory,'  MB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv layer  0  has  2  unique weight values\n",
      "conv layer  1  has  2  unique weight values\n",
      "conv layer  2  has  2  unique weight values\n",
      "conv layer  3  has  2  unique weight values\n",
      "conv layer  4  has  2  unique weight values\n",
      "conv layer  5  has  2  unique weight values\n",
      "conv layer  6  has  2  unique weight values\n",
      "conv layer  7  has  2  unique weight values\n",
      "conv layer  8  has  2  unique weight values\n",
      "conv layer  9  has  2  unique weight values\n",
      "conv layer  10  has  2  unique weight values\n",
      "conv layer  11  has  2  unique weight values\n",
      "conv layer  12  has  2  unique weight values\n",
      "conv layer  13  has  2  unique weight values\n",
      "conv layer  14  has  2  unique weight values\n",
      "conv layer  15  has  2  unique weight values\n",
      "conv layer  16  has  2  unique weight values\n",
      "conv layer  17  has  2  unique weight values\n",
      "conv layer  18  has  2  unique weight values\n",
      "conv layer  19  has  2  unique weight values\n",
      "conv layer  20  has  2  unique weight values\n",
      "conv layer  21  has  2  unique weight values\n",
      "conv layer  22  has  2  unique weight values\n",
      "conv layer  23  has  2  unique weight values\n",
      "conv layer  24  has  2  unique weight values\n",
      "conv layer  25  has  2  unique weight values\n",
      "conv layer  26  has  2  unique weight values\n",
      "conv layer  27  has  2  unique weight values\n",
      "conv layer  28  has  2  unique weight values\n",
      "conv layer  29  has  2  unique weight values\n",
      "conv layer  30  has  2  unique weight values\n",
      "conv layer  31  has  2  unique weight values\n",
      "conv layer  32  has  2  unique weight values\n",
      "conv layer  33  has  2  unique weight values\n",
      "conv layer  34  has  2  unique weight values\n",
      "conv layer  35  has  2  unique weight values\n",
      "One-bit-per-weight Test accuracy (%): 96.86977299880526\n"
     ]
    }
   ],
   "source": [
    "#verify that these 0/1 weights when loaded work as expected:\n",
    "\n",
    "AllParamsDict_loaded=loadmat('FinalModel_allparams.mat')\n",
    "\n",
    "conv_names=[m for m in list(AllParamsDict_loaded.keys()) if any(s in m for s in ['conv2d'])]\n",
    "bn_names=[m for m in list(AllParamsDict_loaded.keys()) if any(s in m for s in ['batch'])]\n",
    "\n",
    "c1=0\n",
    "c2=0\n",
    "for layer in inference_model.layers:\n",
    "    if 'conv2d' in layer.name:\n",
    "        ww=AllParamsDict_loaded[conv_names[c1]].astype('float32')*2.0-1.0\n",
    "        ww=ww*np.sqrt(2.0/np.prod(ww[0].shape[0:3]))\n",
    "        layer.set_weights([ww[0]])\n",
    "        print('conv layer ',c1,' has ', len(np.unique(ww)),' unique weight values')\n",
    "        c1=c1+1\n",
    "    elif 'batch_normalization' in layer.name:\n",
    "        ww=AllParamsDict_loaded[bn_names[c2]]\n",
    "        layer.set_weights(ww)\n",
    "        c2=c2+1\n",
    "\n",
    "#get accuracy:\n",
    "y_pred_val_binary_conv = inference_model.predict(X_val)\n",
    "print('One-bit-per-weight Test accuracy (%):', 100*sum(np.argmax(y_pred_val_binary_conv,-1)==np.argmax(y_val,-1))/y_val.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv layer  0  has  2  unique weight values\n",
      "conv layer  1  has  2  unique weight values\n",
      "conv layer  2  has  2  unique weight values\n",
      "conv layer  3  has  2  unique weight values\n",
      "conv layer  4  has  2  unique weight values\n",
      "conv layer  5  has  2  unique weight values\n",
      "conv layer  6  has  2  unique weight values\n",
      "conv layer  7  has  2  unique weight values\n",
      "conv layer  8  has  2  unique weight values\n",
      "conv layer  9  has  2  unique weight values\n",
      "conv layer  10  has  2  unique weight values\n",
      "conv layer  11  has  2  unique weight values\n",
      "conv layer  12  has  2  unique weight values\n",
      "conv layer  13  has  2  unique weight values\n",
      "conv layer  14  has  2  unique weight values\n",
      "conv layer  15  has  2  unique weight values\n",
      "conv layer  16  has  2  unique weight values\n",
      "conv layer  17  has  2  unique weight values\n",
      "conv layer  18  has  2  unique weight values\n",
      "conv layer  19  has  2  unique weight values\n",
      "conv layer  20  has  2  unique weight values\n",
      "conv layer  21  has  2  unique weight values\n",
      "conv layer  22  has  2  unique weight values\n",
      "conv layer  23  has  2  unique weight values\n",
      "conv layer  24  has  2  unique weight values\n",
      "conv layer  25  has  2  unique weight values\n",
      "conv layer  26  has  2  unique weight values\n",
      "conv layer  27  has  2  unique weight values\n",
      "conv layer  28  has  2  unique weight values\n",
      "conv layer  29  has  2  unique weight values\n",
      "conv layer  30  has  2  unique weight values\n",
      "conv layer  31  has  2  unique weight values\n",
      "conv layer  32  has  2  unique weight values\n",
      "conv layer  33  has  2  unique weight values\n",
      "conv layer  34  has  2  unique weight values\n",
      "conv layer  35  has  2  unique weight values\n",
      "One-bit-per-weight Test accuracy (%): 96.86977299880526\n"
     ]
    }
   ],
   "source": [
    "#final test: we get the same results if the model uses regular conv layers, and not the binarising version:\n",
    "\n",
    "inference_model_regular_conv = model_resnet_updated_all_binary(NumClasses,\n",
    "                         input_shape =[NumFreqBins,None,num_audio_channels], \n",
    "                         num_filters =num_filters,\n",
    "                         wd=wd,binarise_weights=False)\n",
    "\n",
    "\n",
    "c1=0\n",
    "c2=0\n",
    "for layer in inference_model_regular_conv.layers:\n",
    "    if 'conv2d' in layer.name:\n",
    "        ww=AllParamsDict_loaded[conv_names[c1]].astype('float32')*2.0-1.0\n",
    "        ww=ww*np.sqrt(2.0/np.prod(ww[0].shape[0:3]))\n",
    "        layer.set_weights([ww[0]])\n",
    "        print('conv layer ',c1,' has ', len(np.unique(ww)),' unique weight values')\n",
    "        c1=c1+1\n",
    "    elif 'batch_normalization' in layer.name:\n",
    "        ww=AllParamsDict_loaded[bn_names[c2]]\n",
    "        layer.set_weights(ww)\n",
    "        c2=c2+1\n",
    "\n",
    "#get accuracy:\n",
    "y_pred_val_regular_conv = inference_model_regular_conv.predict(X_val)\n",
    "print('One-bit-per-weight Test accuracy (%):', 100*sum(np.argmax(y_pred_val_regular_conv,-1)==np.argmax(y_val,-1))/y_val.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
